{"policy loss": 2.00299072265625, "entropy": 0.017049364745616913, "time steps": 146, "reward": 2.470540806672012, "_timestamp": 1651381762, "_runtime": 3923, "_step": 146}